# Project 45: Tokenization and Text Processing

## Learning Objectives

- Understand tokenization (BPE, WordPiece, SentencePiece)
- Implement basic tokenizer
- Handle special tokens
- Convert between text and tokens
- Prepare text for LLMs

## Problem Description

Tokenization converts text to numbers that models can process. Different strategies (BPE, WordPiece) handle vocabulary efficiently.

## Key Concepts

- Byte Pair Encoding (BPE)
- WordPiece tokenization
- Special tokens (BOS, EOS, PAD)
- Vocabulary management

## Deliverables

Basic tokenizer implementation with encoding/decoding.

## Testing

Run: `pytest test.py -v`
