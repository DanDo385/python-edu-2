# Project 49: LLM Evaluation Metrics

## Learning Objectives

- Understand LLM evaluation metrics
- Implement BLEU score
- Implement ROUGE score
- Perplexity calculation
- Human evaluation considerations

## Problem Description

Evaluating LLMs requires appropriate metrics. BLEU, ROUGE, and perplexity measure different aspects of model performance.

## Key Concepts

- BLEU (precision-based)
- ROUGE (recall-based)
- Perplexity (language modeling)
- Task-specific metrics

## Deliverables

Evaluation metrics implementation (BLEU, ROUGE, perplexity).

## Testing

Run: `pytest test.py -v`
